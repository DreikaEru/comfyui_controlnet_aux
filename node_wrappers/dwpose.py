from ..utils import common_annotator_call, define_preprocessor_inputs, INPUT
import comfy.model_management as model_management
import numpy as np
import warnings
from ..src.custom_controlnet_aux.dwpose import DwposeDetector, AnimalposeDetector
import os
import json
import re
import requests

DWPOSE_MODEL_NAME = "yzd-v/DWPose"

# ------------------------------------------------------------
# ONNXRUNTIME PROVIDERS: detect best available + optional update notice
# ------------------------------------------------------------

# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ onnxruntime:
# - onnxruntime-directml => "DmlExecutionProvider"
# - onnxruntime-gpu (NVIDIA) => "CUDAExecutionProvider" (+ –∏–Ω–æ–≥–¥–∞ TensorrtExecutionProvider)
GPU_PROVIDERS = [
    "TensorrtExecutionProvider",
    "CUDAExecutionProvider",
    "ROCMExecutionProvider",
    "DmlExecutionProvider",          # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: DirectML ‚Üí Dml
    "OpenVINOExecutionProvider",
    "CoreMLExecutionProvider",
    "MIGraphXExecutionProvider",
]

def _version_key(v: str):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–µ—Ä—Å–∏—é '1.17.3' –≤ [1, 17, 3] –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    nums = re.findall(r"\d+", v or "")
    return [int(x) for x in nums] if nums else [0]

def _notify_if_newer_pypi(package_name: str, installed_version: str):
    """
    –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –ø–µ—á–∞—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–∞ PyPI –µ—Å—Ç—å –≤–µ—Ä—Å–∏—è –Ω–æ–≤–µ–µ.
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ–∑–æ–ø–∞—Å–Ω–æ: –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Å–µ—Ç–∏/–±–ª–æ–∫–∏—Ä–æ–≤–∫–µ/–æ—à–∏–±–∫–∞—Ö –º–æ–ª—á–∏—Ç.
    –û—Ç–∫–ª—é—á–µ–Ω–∏–µ: set DWPOSE_NO_UPDATE_CHECK=1
    """
    if os.environ.get("DWPOSE_NO_UPDATE_CHECK", "0") == "1":
        return
    try:
        url = f"https://pypi.org/pypi/{package_name}/json"
        r = requests.get(url, timeout=1.5)
        if r.status_code != 200:
            return
        latest = (r.json().get("info", {}) or {}).get("version", "")
        if latest and _version_key(latest) > _version_key(installed_version):
            print(f"[DWPose] üì¶ Update available for {package_name}: {installed_version} ‚Üí {latest}")
    except Exception:
        return

def _select_best_ort_providers(available):
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–¥ —Å–∏—Å—Ç–µ–º—É.
    –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞:
      TensorRT ‚Üí CUDA ‚Üí ROCm ‚Üí DirectML(DML) ‚Üí OpenVINO ‚Üí CoreML ‚Üí CPU
    """
    available = list(available or [])
    priority = [
        "TensorrtExecutionProvider",
        "CUDAExecutionProvider",
        "ROCMExecutionProvider",
        "DmlExecutionProvider",
        "OpenVINOExecutionProvider",
        "CoreMLExecutionProvider",
        "CPUExecutionProvider",
    ]
    selected = [p for p in priority if p in available]
    if "CPUExecutionProvider" not in selected:
        selected.append("CPUExecutionProvider")
    return selected

def _init_dwpose_onnxruntime_env():
    """
    –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ –∑–∞–ø—É—Å–∫ (DWPOSE_ONNXRT_CHECKED),
    –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤—ã—Å—Ç–∞–≤–ª—è–µ—Ç AUX_ORT_PROVIDERS.
    """
    if os.environ.get("DWPOSE_ONNXRT_CHECKED"):
        return

    try:
        import onnxruntime as ort
        providers = ort.get_available_providers() or []
        selected = _select_best_ort_providers(providers)

        has_accel = any(p != "CPUExecutionProvider" for p in selected)

        if has_accel:
            # –í—ã–≤–æ–¥–∏–º —á–µ—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞—Ö
            print("\n" + "="*60)
            print("ü§ñ DWPOSE ONNXRUNTIME INFO")
            print("="*60)
            print(f"üìã –í—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã —É—Å–∫–æ—Ä–µ–Ω–∏—è: {', '.join(GPU_PROVIDERS)}")
            print(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤ —Å–∏—Å—Ç–µ–º–µ:      {providers if providers else '–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤'}")
            if selected:
                print(f"üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä:     {selected[0]}")
                if len(selected) > 1:
                    print(f"üîß –†–µ–∑–µ—Ä–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã:   {', '.join(selected[1:])}")
            else:
                print("‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã")
            print("="*60 + "\n")

            # –ù–µ –ø–µ—Ä–µ—Ç–∏—Ä–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –∑–∞–¥–∞–ª AUX_ORT_PROVIDERS —Å–∞–º
            if "AUX_ORT_PROVIDERS" not in os.environ:
                os.environ["AUX_ORT_PROVIDERS"] = ",".join(selected)

            # –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
            try:
                import importlib.metadata as imd
                for pkg in ("onnxruntime-directml", "onnxruntime", "onnxruntime-gpu"):
                    try:
                        installed = imd.version(pkg)
                        _notify_if_newer_pypi(pkg, installed)
                    except Exception:
                        pass
            except Exception:
                pass
        else:
            warnings.warn(
                "DWPose: Onnxruntime found but no acceleration providers available "
                f"(providers={providers}); switching to OpenCV CPU. "
                "DWPose might run very slowly"
            )
            os.environ["AUX_ORT_PROVIDERS"] = ""

    except Exception as e:
        warnings.warn(
            "DWPose: Onnxruntime not found or doesn't come with acceleration providers, "
            "switch to OpenCV with CPU device. DWPose might run very slowly"
        )
        os.environ["AUX_ORT_PROVIDERS"] = ""

    os.environ["DWPOSE_ONNXRT_CHECKED"] = "1"

_init_dwpose_onnxruntime_env()

# ------------------------------------------------------------
# Nodes
# ------------------------------------------------------------

class DWPose_Preprocessor:
    @classmethod
    def INPUT_TYPES(s):
        return define_preprocessor_inputs(
            detect_hand=INPUT.COMBO(["enable", "disable"]),
            detect_body=INPUT.COMBO(["enable", "disable"]),
            detect_face=INPUT.COMBO(["enable", "disable"]),
            resolution=INPUT.RESOLUTION(),
            bbox_detector=INPUT.COMBO(
                ["None"] + ["yolox_l.torchscript.pt", "yolox_l.onnx", "yolo_nas_l_fp16.onnx", "yolo_nas_m_fp16.onnx", "yolo_nas_s_fp16.onnx"],
                default="yolox_l.onnx"
            ),
            pose_estimator=INPUT.COMBO(
                ["dw-ll_ucoco_384_bs5.torchscript.pt", "dw-ll_ucoco_384.onnx", "dw-ll_ucoco.onnx"],
                default="dw-ll_ucoco_384_bs5.torchscript.pt"
            ),
            scale_stick_for_xinsr_cn=INPUT.COMBO(["disable", "enable"])
        )

    RETURN_TYPES = ("IMAGE", "POSE_KEYPOINT")
    FUNCTION = "estimate_pose"

    CATEGORY = "ControlNet Preprocessors/Faces and Poses Estimators"

    def estimate_pose(self, image, detect_hand="enable", detect_body="enable", detect_face="enable",
                      resolution=512, bbox_detector="yolox_l.onnx", pose_estimator="dw-ll_ucoco_384.onnx",
                      scale_stick_for_xinsr_cn="disable", **kwargs):
        if bbox_detector == "None":
            yolo_repo = DWPOSE_MODEL_NAME
        elif bbox_detector == "yolox_l.onnx":
            yolo_repo = DWPOSE_MODEL_NAME
        elif "yolox" in bbox_detector:
            yolo_repo = "hr16/yolox-onnx"
        elif "yolo_nas" in bbox_detector:
            yolo_repo = "hr16/yolo-nas-fp16"
        else:
            raise NotImplementedError(f"Download mechanism for {bbox_detector}")

        if pose_estimator == "dw-ll_ucoco_384.onnx":
            pose_repo = DWPOSE_MODEL_NAME
        elif pose_estimator.endswith(".onnx"):
            pose_repo = "hr16/UnJIT-DWPose"
        elif pose_estimator.endswith(".torchscript.pt"):
            pose_repo = "hr16/DWPose-TorchScript-BatchSize5"
        else:
            raise NotImplementedError(f"Download mechanism for {pose_estimator}")

        model = DwposeDetector.from_pretrained(
            pose_repo,
            yolo_repo,
            det_filename=(None if bbox_detector == "None" else bbox_detector),
            pose_filename=pose_estimator,
            torchscript_device=model_management.get_torch_device()
        )

        detect_hand = detect_hand == "enable"
        detect_body = detect_body == "enable"
        detect_face = detect_face == "enable"
        scale_stick_for_xinsr_cn = scale_stick_for_xinsr_cn == "enable"

        self.openpose_dicts = []

        def func(image, **kwargs):
            pose_img, openpose_dict = model(image, **kwargs)
            self.openpose_dicts.append(openpose_dict)
            return pose_img

        out = common_annotator_call(
            func,
            image,
            include_hand=detect_hand,
            include_face=detect_face,
            include_body=detect_body,
            image_and_json=True,
            resolution=resolution,
            xinsr_stick_scaling=scale_stick_for_xinsr_cn
        )
        del model
        return {
            "ui": {"openpose_json": [json.dumps(self.openpose_dicts, indent=4)]},
            "result": (out, self.openpose_dicts)
        }

class AnimalPose_Preprocessor:
    @classmethod
    def INPUT_TYPES(s):
        return define_preprocessor_inputs(
            bbox_detector=INPUT.COMBO(
                ["None"] + ["yolox_l.torchscript.pt", "yolox_l.onnx", "yolo_nas_l_fp16.onnx", "yolo_nas_m_fp16.onnx", "yolo_nas_s_fp16.onnx"],
                default="yolox_l.torchscript.pt"
            ),
            pose_estimator=INPUT.COMBO(
                ["rtmpose-m_ap10k_256_bs5.torchscript.pt", "rtmpose-m_ap10k_256.onnx"],
                default="rtmpose-m_ap10k_256_bs5.torchscript.pt"
            ),
            resolution=INPUT.RESOLUTION()
        )

    RETURN_TYPES = ("IMAGE", "POSE_KEYPOINT")
    FUNCTION = "estimate_pose"

    CATEGORY = "ControlNet Preprocessors/Faces and Poses Estimators"

    def estimate_pose(self, image, resolution=512, bbox_detector="yolox_l.onnx",
                      pose_estimator="rtmpose-m_ap10k_256.onnx", **kwargs):
        if bbox_detector == "None":
            yolo_repo = DWPOSE_MODEL_NAME
        elif bbox_detector == "yolox_l.onnx":
            yolo_repo = DWPOSE_MODEL_NAME
        elif "yolox" in bbox_detector:
            yolo_repo = "hr16/yolox-onnx"
        elif "yolo_nas" in bbox_detector:
            yolo_repo = "hr16/yolo-nas-fp16"
        else:
            raise NotImplementedError(f"Download mechanism for {bbox_detector}")

        if pose_estimator == "dw-ll_ucoco_384.onnx":
            pose_repo = DWPOSE_MODEL_NAME
        elif pose_estimator.endswith(".onnx"):
            pose_repo = "hr16/UnJIT-DWPose"
        elif pose_estimator.endswith(".torchscript.pt"):
            pose_repo = "hr16/DWPose-TorchScript-BatchSize5"
        else:
            raise NotImplementedError(f"Download mechanism for {pose_estimator}")

        model = AnimalposeDetector.from_pretrained(
            pose_repo,
            yolo_repo,
            det_filename=(None if bbox_detector == "None" else bbox_detector),
            pose_filename=pose_estimator,
            torchscript_device=model_management.get_torch_device()
        )

        self.openpose_dicts = []

        def func(image, **kwargs):
            pose_img, openpose_dict = model(image, **kwargs)
            self.openpose_dicts.append(openpose_dict)
            return pose_img

        out = common_annotator_call(func, image, image_and_json=True, resolution=resolution)
        del model
        return {
            "ui": {"openpose_json": [json.dumps(self.openpose_dicts, indent=4)]},
            "result": (out, self.openpose_dicts)
        }

NODE_CLASS_MAPPINGS = {
    "DWPreprocessor": DWPose_Preprocessor,
    "AnimalPosePreprocessor": AnimalPose_Preprocessor
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "DWPreprocessor": "DWPose Estimator",
    "AnimalPosePreprocessor": "AnimalPose Estimator (AP10K)"
}
